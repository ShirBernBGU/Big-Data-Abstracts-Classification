{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b344d0",
   "metadata": {},
   "source": [
    "# installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a3b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# # ------------------------------------------------------------\n",
    "# # 0. Install (once) if needed\n",
    "# !pip install -q transformers datasets evaluate scikit-learn torch\n",
    "# # ------------------------------------------------------------\n",
    "# !pip install transformers[torch]\n",
    "# !pip install accelerate>=0.26.0\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b038ec",
   "metadata": {},
   "source": [
    "# uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db261c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Y1  Y2    Y    Domain                     area  \\\n",
      "0   0  12   12       CS    Symbolic computation     \n",
      "1   5   2   74  Medical     Alzheimer's Disease     \n",
      "2   4   7   68    Civil          Green Building     \n",
      "3   1  10   26      ECE          Electric motor     \n",
      "4   5  43  115  Medical     Parkinson's Disease     \n",
      "\n",
      "                                            keywords  \\\n",
      "0   (2+1)-dimensional non-linear optical waves; e...   \n",
      "1   Aging; Tau; Amyloid; PET; Alzheimer's disease...   \n",
      "2   LED lighting system; PV system; Distributed l...   \n",
      "3   NdFeB magnets; Electric motor; Electric vehic...   \n",
      "4   Parkinson's disease; dyskinesia; adenosine A(...   \n",
      "\n",
      "                                            Abstract  \n",
      "0  (2 + 1)-dimensional non-linear optical waves t...  \n",
      "1  (beta-amyloid (A beta) and tau pathology becom...  \n",
      "2  (D)ecreasing of energy consumption and environ...  \n",
      "3  (Hybrid) electric vehicles are assumed to play...  \n",
      "4  (L)-3,4-Dihydroxyphenylalanine ((L)-DOPA) rema...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use raw string (r'...') to avoid issues with backslashes in Windows paths\n",
    "# file_path = r'FilteredData100.xlsx'\n",
    "file_path = r'/home/eldord/Big-Data-Abstracts-Classification/data/FilteredData100.xlsx' # Adjust the path as needed\n",
    "\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Preview the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943fb010",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd42074",
   "metadata": {},
   "source": [
    "## domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c2b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eldord/.conda/envs/denisenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 32634/32634 [00:08<00:00, 3728.65 examples/s]\n",
      "Map: 100%|██████████| 6993/6993 [00:01<00:00, 3537.72 examples/s]\n",
      "Map: 100%|██████████| 6993/6993 [00:01<00:00, 3760.13 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 27.7MB/s]\n",
      "Downloading builder script: 100%|██████████| 6.79k/6.79k [00:00<00:00, 39.4MB/s]\n",
      "/tmp/ipykernel_1911966/526516142.py:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[zero] Evaluating on validation set …\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_loss           : 2.1356\n",
      "zero_model_preparation_time: 0.0024\n",
      "zero_accuracy       : 0.0781\n",
      "zero_macro_f1       : 0.0329\n",
      "zero_runtime        : 28.0963\n",
      "zero_samples_per_second: 248.8940\n",
      "zero_steps_per_second: 31.1430\n",
      "\n",
      "[zero] Evaluating on test set …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1911966/526516142.py:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_loss           : 2.1388\n",
      "zero_model_preparation_time: 0.0022\n",
      "zero_accuracy       : 0.0766\n",
      "zero_macro_f1       : 0.0324\n",
      "zero_runtime        : 23.7920\n",
      "zero_samples_per_second: 293.9220\n",
      "zero_steps_per_second: 36.7770\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, random, numpy as np, pandas as pd, torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "import evaluate\n",
    "\n",
    "# --------------------------- CONFIG --------------------------\n",
    "SEED         = 42\n",
    "MODEL_NAME   = \"bert-base-uncased\"          # vanilla BERT\n",
    "LABEL_COL    = \"Domain\"                     # <- CHANGE if your label lives elsewhere\n",
    "TEXT_COL     = \"Abstract\"\n",
    "BATCH_SIZE   = 8\n",
    "EPOCHS       = 3\n",
    "LR           = 2e-5\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# 1.-- Prepare the data -------------------------------------------------------\n",
    "assert LABEL_COL in df.columns, f\"{LABEL_COL} not found in dataframe\"\n",
    "\n",
    "# map label strings → integer ids\n",
    "label_list        = sorted(df[LABEL_COL].unique())\n",
    "label2id          = {l:i for i,l in enumerate(label_list)}\n",
    "id2label          = {i:l for l,i in label2id.items()}\n",
    "df[\"label\"]       = df[LABEL_COL].map(label2id)\n",
    "\n",
    "# train / val / test split (70/15/15)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, stratify=df[\"label\"],\n",
    "                                     random_state=SEED)\n",
    "val_df, test_df   = train_test_split(temp_df, test_size=0.50, stratify=temp_df[\"label\"],\n",
    "                                     random_state=SEED)\n",
    "\n",
    "hf_dset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df[[TEXT_COL, \"label\"]]),\n",
    "    \"validation\": Dataset.from_pandas(val_df[[TEXT_COL, \"label\"]]),\n",
    "    \"test\": Dataset.from_pandas(test_df[[TEXT_COL, \"label\"]])\n",
    "})\n",
    "\n",
    "# 2.-- Tokenisation -----------------------------------------------------------\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tok(batch[TEXT_COL], truncation=True)\n",
    "hf_dset_tok = hf_dset.map(tokenize, batched=True, remove_columns=[TEXT_COL])\n",
    "data_collator = DataCollatorWithPadding(tok)\n",
    "\n",
    "# 3.-- Model -----------------------------------------------------------------\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels=len(label_list),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id)\n",
    "\n",
    "metric_acc  = evaluate.load(\"accuracy\")\n",
    "metric_f1   = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"macro_f1\": metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "# 4.-- Helper: quick evaluation ---------------------------------------------\n",
    "def quick_eval(split: str, tag: str):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tok,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    print(f\"\\n[{tag}] Evaluating on {split} set …\")\n",
    "    metrics = trainer.evaluate(hf_dset_tok[split], metric_key_prefix=tag)\n",
    "    for k,v in metrics.items():\n",
    "        if k.startswith(tag):\n",
    "            print(f\"{k:<20}: {v:.4f}\")\n",
    "    return metrics\n",
    "\n",
    "# Baseline (zero-shot) on val & test\n",
    "baseline_val  = quick_eval(\"validation\", tag=\"zero\")\n",
    "baseline_test = quick_eval(\"test\",        tag=\"zero\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c25b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1911966/2879497533.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12240' max='12240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12240/12240 18:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.556800</td>\n",
       "      <td>0.351497</td>\n",
       "      <td>0.896039</td>\n",
       "      <td>0.896640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.365154</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.912850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.411463</td>\n",
       "      <td>0.913199</td>\n",
       "      <td>0.916731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[fine] Evaluating on validation set …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1911966/526516142.py:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_loss           : 0.4115\n",
      "fine_model_preparation_time: 0.0022\n",
      "fine_accuracy       : 0.9132\n",
      "fine_macro_f1       : 0.9167\n",
      "fine_runtime        : 23.7944\n",
      "fine_samples_per_second: 293.8930\n",
      "fine_steps_per_second: 36.7730\n",
      "\n",
      "[fine] Evaluating on test set …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1911966/526516142.py:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_loss           : 0.3970\n",
      "fine_model_preparation_time: 0.0022\n",
      "fine_accuracy       : 0.9143\n",
      "fine_macro_f1       : 0.9169\n",
      "fine_runtime        : 23.8635\n",
      "fine_samples_per_second: 293.0420\n",
      "fine_steps_per_second: 36.6670\n",
      "\n",
      "=== VALIDATION SET ===\n",
      "  accuracy: 0.0781 → 0.9132   (Δ +0.8351)\n",
      "  macro_f1: 0.0329 → 0.9167   (Δ +0.8839)\n",
      "\n",
      "=== TEST SET ===\n",
      "  accuracy: 0.0766 → 0.9143   (Δ +0.8377)\n",
      "  macro_f1: 0.0324 → 0.9169   (Δ +0.8845)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.-- Fine-tune --------------------------------------------------------------\n",
    "args = TrainingArguments(\n",
    "    output_dir            = \"bert_abstract_cls\",\n",
    "    eval_strategy   = \"epoch\",\n",
    "    save_strategy         = \"no\",\n",
    "    learning_rate         = LR,\n",
    "    per_device_train_batch_size = BATCH_SIZE,\n",
    "    per_device_eval_batch_size  = BATCH_SIZE,\n",
    "    num_train_epochs      = EPOCHS,\n",
    "    seed                  = SEED,\n",
    "    weight_decay          = 0.01,\n",
    "    logging_steps         = 50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model               = model,\n",
    "    args                = args,\n",
    "    train_dataset       = hf_dset_tok[\"train\"],\n",
    "    eval_dataset        = hf_dset_tok[\"validation\"],\n",
    "    tokenizer           = tok,\n",
    "    data_collator       = data_collator,\n",
    "    compute_metrics     = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 6.-- Post-training evaluation ----------------------------------------------\n",
    "fin_val  = quick_eval(\"validation\", tag=\"fine\")\n",
    "fin_test = quick_eval(\"test\",        tag=\"fine\")\n",
    "\n",
    "# 7.-- Simple side-by-side comparison ----------------------------------------\n",
    "def compare(before, after, split):\n",
    "    print(f\"\\n=== {split.upper()} SET ===\")\n",
    "    for m in (\"accuracy\",\"macro_f1\"):\n",
    "        b = before[f\"zero_{m}\"]; a = after[f\"fine_{m}\"]\n",
    "        diff = a - b\n",
    "        print(f\"{m:>10}: {b:.4f} → {a:.4f}   (Δ {diff:+.4f})\")\n",
    "\n",
    "compare(baseline_val,  fin_val,  \"validation\")\n",
    "compare(baseline_test, fin_test, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aace43",
   "metadata": {},
   "source": [
    "## area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, random, numpy as np, pandas as pd, torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "import evaluate\n",
    "\n",
    "# --------------------------- CONFIG --------------------------\n",
    "SEED         = 42\n",
    "MODEL_NAME   = \"bert-base-uncased\"          # vanilla BERT\n",
    "LABEL_COL    = \"area\"                     # <- CHANGE if your label lives elsewhere\n",
    "TEXT_COL     = \"Abstract\"\n",
    "BATCH_SIZE   = 8\n",
    "EPOCHS       = 3\n",
    "LR           = 2e-5\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# 1.-- Prepare the data -------------------------------------------------------\n",
    "assert LABEL_COL in df.columns, f\"{LABEL_COL} not found in dataframe\"\n",
    "\n",
    "# map label strings → integer ids\n",
    "label_list        = sorted(df[LABEL_COL].unique())\n",
    "label2id          = {l:i for i,l in enumerate(label_list)}\n",
    "id2label          = {i:l for l,i in label2id.items()}\n",
    "df[\"label\"]       = df[LABEL_COL].map(label2id)\n",
    "\n",
    "# train / val / test split (70/15/15)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, stratify=df[\"label\"],\n",
    "                                     random_state=SEED)\n",
    "val_df, test_df   = train_test_split(temp_df, test_size=0.50, stratify=temp_df[\"label\"],\n",
    "                                     random_state=SEED)\n",
    "\n",
    "hf_dset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df[[TEXT_COL, \"label\"]]),\n",
    "    \"validation\": Dataset.from_pandas(val_df[[TEXT_COL, \"label\"]]),\n",
    "    \"test\": Dataset.from_pandas(test_df[[TEXT_COL, \"label\"]])\n",
    "})\n",
    "\n",
    "# 2.-- Tokenisation -----------------------------------------------------------\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tok(batch[TEXT_COL], truncation=True)\n",
    "hf_dset_tok = hf_dset.map(tokenize, batched=True, remove_columns=[TEXT_COL])\n",
    "data_collator = DataCollatorWithPadding(tok)\n",
    "\n",
    "# 3.-- Model -----------------------------------------------------------------\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels=len(label_list),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id)\n",
    "\n",
    "metric_acc  = evaluate.load(\"accuracy\")\n",
    "metric_f1   = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"macro_f1\": metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "# 4.-- Helper: quick evaluation ---------------------------------------------\n",
    "def quick_eval(split: str, tag: str):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tok,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    print(f\"\\n[{tag}] Evaluating on {split} set …\")\n",
    "    metrics = trainer.evaluate(hf_dset_tok[split], metric_key_prefix=tag)\n",
    "    for k,v in metrics.items():\n",
    "        if k.startswith(tag):\n",
    "            print(f\"{k:<20}: {v:.4f}\")\n",
    "    return metrics\n",
    "\n",
    "# Baseline (zero-shot) on val & test\n",
    "baseline_val  = quick_eval(\"validation\", tag=\"zero\")\n",
    "baseline_test = quick_eval(\"test\",        tag=\"zero\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a3544",
   "metadata": {},
   "source": [
    "# BERT-base-uncased-MNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d993d",
   "metadata": {},
   "source": [
    "## domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ed9d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eldord/.conda/envs/denisenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain labels: ['CS', 'Civil', 'ECE', 'MAE', 'Medical', 'Psychology', 'biochemistry']\n",
      "Loaded 46,620 rows   –   7 unique labels:\n",
      "['CS', 'Civil', 'ECE', 'MAE', 'Medical', 'Psychology', 'biochemistry']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ZERO-SHOT (domain-level)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zero-shot:   9%|▉         | 10/110 [00:15<02:36,  1.57s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "zero-shot: 100%|██████████| 110/110 [02:51<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: {'zero_accuracy': 0.25368225368225367, 'zero_macro_f1': 0.1847543961810419}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zero-shot: 100%|██████████| 110/110 [02:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:       {'zero_accuracy': 0.2621192621192621, 'zero_macro_f1': 0.19189073650322144}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 32634/32634 [00:24<00:00, 1336.95 examples/s]\n",
      "Map: 100%|██████████| 6993/6993 [00:05<00:00, 1302.52 examples/s]\n",
      "Map: 100%|██████████| 6993/6993 [00:05<00:00, 1328.07 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at textattack/bert-base-uncased-MNLI and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_3375574/23494557.py:181: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, args=args,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40800' max='40800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40800/40800 1:01:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.382340</td>\n",
       "      <td>0.889175</td>\n",
       "      <td>0.890532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.370578</td>\n",
       "      <td>0.907050</td>\n",
       "      <td>0.909362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.426103</td>\n",
       "      <td>0.904619</td>\n",
       "      <td>0.906551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.494778</td>\n",
       "      <td>0.907479</td>\n",
       "      <td>0.910257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>0.573084</td>\n",
       "      <td>0.903332</td>\n",
       "      <td>0.907134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.607182</td>\n",
       "      <td>0.906621</td>\n",
       "      <td>0.910623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.681293</td>\n",
       "      <td>0.907622</td>\n",
       "      <td>0.910343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.711535</td>\n",
       "      <td>0.908766</td>\n",
       "      <td>0.912104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.793020</td>\n",
       "      <td>0.911912</td>\n",
       "      <td>0.915305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.808164</td>\n",
       "      <td>0.909481</td>\n",
       "      <td>0.912498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> POST-TUNING EVALUATION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VALIDATION ===\n",
      "  accuracy: 0.2537 → 0.9095   (Δ +0.6558)\n",
      "  macro_f1: 0.1848 → 0.9125   (Δ +0.7277)\n",
      "\n",
      "=== TEST ===\n",
      "  accuracy: 0.2621 → 0.9105   (Δ +0.6484)\n",
      "  macro_f1: 0.1919 → 0.9122   (Δ +0.7203)\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# Web-of-Science   ·   Domain-level baseline → fine-tune\n",
    "# ===========================================================================\n",
    "\n",
    "# !pip install -qq datasets transformers evaluate tqdm\n",
    "\n",
    "import random, os, numpy as np, torch, evaluate\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, pipeline)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED            = 42\n",
    "VARIANT         = \"WOS46985\"               # \"WOS11967\" / \"WOS5736\" also work\n",
    "ZS_MODEL_NAME   = \"textattack/bert-base-uncased-MNLI\"\n",
    "BATCH_SIZE_ZS   = 64                       # >= 32 is safe with a 12-GB GPU\n",
    "BATCH_SIZE_FT   = 8\n",
    "EPOCHS          = 10\n",
    "LR              = 2e-5\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1.  LOAD YOUR EXCEL SHEET  (instead of load_dataset)  ----------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "SEED = 42                                    # keep the same seed everywhere\n",
    "TEXT_COL  = \"Abstract\"                       # column that holds the text\n",
    "LABEL_COL = \"Domain\"                         # ← change to \"area\" later on\n",
    "FILE_PATH = r\"FilteredData100.xlsx\"          # your file\n",
    "\n",
    "# -- read the sheet ----------------------------------------------------------\n",
    "df = pd.read_excel(FILE_PATH)[[TEXT_COL, LABEL_COL]].dropna()\n",
    "\n",
    "# -- label ↔ id mappings -----------------------------------------------------\n",
    "# label_list = sorted(df[LABEL_COL].unique())\n",
    "# label2id   = {l:i for i,l in enumerate(label_list)}\n",
    "# id2label   = {i:l for l,i in label2id.items()}\n",
    "# df[\"label\"] = df[LABEL_COL].map(label2id)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# clean up label strings and build the canonical list  -------------\n",
    "# ------------------------------------------------------------------\n",
    "df[LABEL_COL] = df[LABEL_COL].str.strip()            # remove leading/trailing spaces\n",
    "label_list  = sorted(df[LABEL_COL].unique())         # canonical list (7 labels)\n",
    "label2id    = {l: i for i, l in enumerate(label_list)}\n",
    "id2label    = {i: l for l, i in label2id.items()}\n",
    "df[\"label\"] = df[LABEL_COL].map(label2id)\n",
    "\n",
    "print(\"Domain labels:\", label_list)   # sanity-check\n",
    "\n",
    "\n",
    "# -- split 70 / 15 / 15 ------------------------------------------------------\n",
    "train_df, temp_df = train_test_split(\n",
    "        df, test_size=0.30, stratify=df[\"label\"], random_state=SEED)\n",
    "val_df,   test_df = train_test_split(\n",
    "        temp_df, test_size=0.50, stratify=temp_df[\"label\"], random_state=SEED)\n",
    "\n",
    "hf_dset = DatasetDict({\n",
    "    \"train\":      Dataset.from_pandas(train_df[[TEXT_COL, \"label\"]],\n",
    "                                      preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df[[TEXT_COL, \"label\"]],\n",
    "                                      preserve_index=False),\n",
    "    \"test\":       Dataset.from_pandas(test_df[[TEXT_COL, \"label\"]],\n",
    "                                      preserve_index=False),\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows   –   {len(label_list)} unique labels:\")\n",
    "print(label_list)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2.  ZERO-SHOT evaluation with MNLI-BERT   (fast: N × 7 only) --------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "mnli = AutoModelForSequenceClassification.from_pretrained(ZS_MODEL_NAME)\n",
    "mnli.config.label2id = {\"contradiction\": 0, \"neutral\": 1, \"entailment\": 2}\n",
    "mnli.config.id2label = {v:k for k,v in mnli.config.label2id.items()}\n",
    "\n",
    "zs_pipe = pipeline(\"zero-shot-classification\",\n",
    "                   model     = mnli,\n",
    "                   tokenizer = ZS_MODEL_NAME,\n",
    "                   device    = 0 if torch.cuda.is_available() else -1,\n",
    "                   batch_size= BATCH_SIZE_ZS)\n",
    "\n",
    "def zs_predict(texts, labels=label_list):\n",
    "    preds = []\n",
    "    for i in tqdm(range(0, len(texts), BATCH_SIZE_ZS), desc=\"zero-shot\"):\n",
    "        chunk = texts[i:i+BATCH_SIZE_ZS]\n",
    "        outs  = zs_pipe(chunk,\n",
    "                        candidate_labels = labels,\n",
    "                        hypothesis_template = \"This abstract is about {}.\",\n",
    "                        multi_label=False)\n",
    "        preds.extend(label2id[o[\"labels\"][0]] for o in outs)\n",
    "    return preds\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\");  metric_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "# def eval_zs(split):\n",
    "#     refs  = hf_dset[split][\"label\"]\n",
    "#     preds = zs_predict(hf_dset[split][\"text\"])\n",
    "#     return {\n",
    "#         \"zero_accuracy\": metric_acc.compute(predictions=preds, references=refs)[\"accuracy\"],\n",
    "#         \"zero_macro_f1\": metric_f1.compute(predictions=preds, references=refs,\n",
    "#                                            average=\"macro\")[\"f1\"]\n",
    "#     }\n",
    "\n",
    "def eval_zs(split):\n",
    "    refs  = hf_dset[split][\"label\"]\n",
    "    preds = zs_predict(hf_dset[split][TEXT_COL])     # ← changed\n",
    "    return {\n",
    "        \"zero_accuracy\": metric_acc.compute(predictions=preds, references=refs)[\"accuracy\"],\n",
    "        \"zero_macro_f1\": metric_f1.compute(predictions=preds, references=refs,\n",
    "                                           average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "print(\"\\n>>> ZERO-SHOT (domain-level)\")\n",
    "baseline_val  = eval_zs(\"validation\");  print(\"validation:\", baseline_val)\n",
    "baseline_test = eval_zs(\"test\");        print(\"test:      \", baseline_test)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3.  Tokeniser & fine-tune --------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "tok = AutoTokenizer.from_pretrained(ZS_MODEL_NAME)\n",
    "\n",
    "# def tok_fn(batch): return tok(batch[\"text\"], truncation=True)\n",
    "# ds_tok = hf_dset.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "def tok_fn(batch):                       # tokenise *Abstract* column\n",
    "    return tok(batch[TEXT_COL], truncation=True)\n",
    "\n",
    "ds_tok = hf_dset.map(tok_fn, batched=True, remove_columns=[TEXT_COL])\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "collator = DataCollatorWithPadding(tok)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            ZS_MODEL_NAME,\n",
    "            # num_labels = len(dom_names),\n",
    "            num_labels = len(label_list),  # 7-way classification\n",
    "            id2label   = id2label,\n",
    "            label2id   = label2id,\n",
    "            ignore_mismatched_sizes = True)          # swaps 3-way head → 7-way\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     preds = np.argmax(logits, axis=-1)\n",
    "#     return {\"accuracy\": metric_acc.compute(preds, labels)[\"accuracy\"],\n",
    "#             \"macro_f1\": metric_f1.compute(preds, labels, average=\"macro\")[\"f1\"]}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=preds,\n",
    "                                       references=labels)[\"accuracy\"],\n",
    "        \"macro_f1\": metric_f1.compute(predictions=preds,\n",
    "                                      references=labels,\n",
    "                                      average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir                 = \"bert_wos_domains\",\n",
    "    learning_rate              = LR,\n",
    "    per_device_train_batch_size= BATCH_SIZE_FT,\n",
    "    per_device_eval_batch_size = BATCH_SIZE_FT,\n",
    "    eval_strategy        = \"epoch\",\n",
    "    save_strategy              = \"epoch\",\n",
    "    num_train_epochs           = EPOCHS,\n",
    "    seed                       = SEED,\n",
    "    weight_decay               = 0.01,\n",
    "    logging_steps              = 100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=args,\n",
    "                  train_dataset = ds_tok[\"train\"],\n",
    "                  eval_dataset  = ds_tok[\"validation\"],\n",
    "                  tokenizer     = tok,\n",
    "                  data_collator = collator,\n",
    "                  compute_metrics = compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n>>> POST-TUNING EVALUATION\")\n",
    "fin_val  = trainer.evaluate(ds_tok[\"validation\"], metric_key_prefix=\"fine\")\n",
    "fin_test = trainer.evaluate(ds_tok[\"test\"],        metric_key_prefix=\"fine\")\n",
    "\n",
    "def compare(before, after, split):\n",
    "    print(f\"\\n=== {split.upper()} ===\")\n",
    "    for m in (\"accuracy\", \"macro_f1\"):\n",
    "        b = before[\"zero_\"+m];  a = after[\"fine_\"+m]\n",
    "        print(f\"{m:>10}: {b:.4f} → {a:.4f}   (Δ {a-b:+.4f})\")\n",
    "\n",
    "compare(baseline_val,  fin_val,  \"validation\")\n",
    "compare(baseline_test, fin_test, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5eeb38",
   "metadata": {},
   "source": [
    "## area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efeb74bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eldord/.conda/envs/denisenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 46,620 rows   –   130 unique labels:\n",
      "['Addiction', 'Algorithm design', 'Allergies', \"Alzheimer's Disease\", 'Ambient Intelligence', 'Analog signal processing', 'Ankylosing Spondylitis', 'Antisocial personality disorder', 'Anxiety', 'Asthma', 'Atopic Dermatitis', 'Atrial Fibrillation', 'Attention', 'Autism', 'Bioinformatics', 'Bipolar Disorder', 'Birth Control', 'Borderline personality disorder', 'Cancer', 'Cell biology', 'Child abuse', \"Children's Health\", 'Computer graphics', 'Computer programming', 'Computer vision', 'Construction Management', 'Control engineering', \"Crohn's Disease\", 'Cryptography', 'Data structures', 'Dementia', 'Depression', 'Diabetes', 'Digital control', 'Distributed computing', 'Eating disorders', 'Electric motor', 'Electrical circuits', 'Electrical generator', 'Electrical network', 'Electricity', 'Emergency Contraception', 'Enzymology', 'False memories', 'Fluid mechanics', 'Fungal Infection', 'Gender roles', 'Genetics', 'Geotextile', 'Green Building', 'HIV/AIDS', 'Headache', 'Healthy Sleep', 'Heart Disease', 'Hepatitis C', 'Hereditary Angioedema', 'Human Metabolism', 'Hydraulics', 'Hypothyroidism', 'Idiopathic Pulmonary Fibrosis', 'Image processing', 'Immunology', 'Internal combustion engine', 'Irritable Bowel Syndrome', 'Leadership', 'Low Testosterone', 'Lymphoma', 'Machine design', 'Machine learning', 'Manufacturing engineering', 'Materials Engineering', 'Media violence', 'Medicare', 'Menopause', 'Mental Health', 'Microcontroller', 'Migraine', 'Molecular biology', 'Multiple Sclerosis', 'Myelofibrosis', 'Nonverbal communication', 'Northern blotting', 'Operating systems', 'Operational amplifier', 'Osteoarthritis', 'Osteoporosis', 'Overactive Bladder', 'PID controller', 'Parallel computing', 'Parenting', \"Parkinson's Disease\", 'Person perception', 'Polycythemia Vera', 'Polymerase chain reaction', 'Prejudice', 'Prenatal development', 'Problem-solving', 'Prosocial behavior', 'Psoriasis', 'Psoriatic Arthritis', 'Rainwater Harvesting', 'Relational databases', 'Remote Sensing', 'Rheumatoid Arthritis', 'Satellite radio', 'Schizophrenia', 'Seasonal affective disorder', 'Senior Health', 'Signal-flow graph', 'Skin Care', 'Smart Material', 'Smoking Cessation', 'Social cognition', 'Software engineering', 'Solar Energy', 'Southern blotting', 'Sports Injuries', 'Sprains and Strains', 'State space representation', 'Stealth Technology', 'Strength of materials', 'Stress Management', 'Suspension Bridge', 'Symbolic computation', 'System identification', 'Thermodynamics', 'Water Pollution', 'Weight Loss', 'computer-aided design', 'network security']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ZERO-SHOT (domain-level)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zero-shot:   9%|▉         | 10/110 [03:52<39:18, 23.59s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "zero-shot: 100%|██████████| 110/110 [41:26<00:00, 22.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: {'zero_accuracy': 0.009867009867009866, 'zero_macro_f1': 0.007130797996498986}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zero-shot: 100%|██████████| 110/110 [41:05<00:00, 22.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:       {'zero_accuracy': 0.011011011011011011, 'zero_macro_f1': 0.00813028580260372}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 32634/32634 [00:24<00:00, 1316.34 examples/s]\n",
      "Map: 100%|██████████| 6993/6993 [00:05<00:00, 1326.87 examples/s]\n",
      "Map: 100%|██████████| 6993/6993 [00:05<00:00, 1327.30 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at textattack/bert-base-uncased-MNLI and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([130, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([130]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_3543511/1830725318.py:197: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, args=args,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40800' max='40800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40800/40800 1:01:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.215200</td>\n",
       "      <td>1.122410</td>\n",
       "      <td>0.774346</td>\n",
       "      <td>0.750035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.778800</td>\n",
       "      <td>0.869723</td>\n",
       "      <td>0.807522</td>\n",
       "      <td>0.799661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.857541</td>\n",
       "      <td>0.817532</td>\n",
       "      <td>0.808285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.894270</td>\n",
       "      <td>0.821393</td>\n",
       "      <td>0.812910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>0.984421</td>\n",
       "      <td>0.823109</td>\n",
       "      <td>0.813740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>1.029975</td>\n",
       "      <td>0.821393</td>\n",
       "      <td>0.812302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>1.065495</td>\n",
       "      <td>0.827256</td>\n",
       "      <td>0.818446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>1.103335</td>\n",
       "      <td>0.828257</td>\n",
       "      <td>0.820075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>1.145008</td>\n",
       "      <td>0.825540</td>\n",
       "      <td>0.817305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>1.156214</td>\n",
       "      <td>0.827399</td>\n",
       "      <td>0.819137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> POST-TUNING EVALUATION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1750' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875/875 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VALIDATION ===\n",
      "  accuracy: 0.0099 → 0.8274   (Δ +0.8175)\n",
      "  macro_f1: 0.0071 → 0.8191   (Δ +0.8120)\n",
      "\n",
      "=== TEST ===\n",
      "  accuracy: 0.0110 → 0.8215   (Δ +0.8105)\n",
      "  macro_f1: 0.0081 → 0.8114   (Δ +0.8033)\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# Web-of-Science   ·   Domain-level baseline → fine-tune\n",
    "# ===========================================================================\n",
    "\n",
    "# !pip install -qq datasets transformers evaluate tqdm\n",
    "\n",
    "import random, os, numpy as np, torch, evaluate\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, pipeline)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED            = 42\n",
    "VARIANT         = \"WOS46985\"               # \"WOS11967\" / \"WOS5736\" also work\n",
    "ZS_MODEL_NAME   = \"textattack/bert-base-uncased-MNLI\"\n",
    "BATCH_SIZE_ZS   = 64                       # >= 32 is safe with a 12-GB GPU\n",
    "BATCH_SIZE_FT   = 8\n",
    "EPOCHS          = 10\n",
    "LR              = 2e-5\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1.  LOAD YOUR EXCEL SHEET  (instead of load_dataset)  ----------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "SEED = 42                                    # keep the same seed everywhere\n",
    "TEXT_COL  = \"Abstract\"                       # column that holds the text\n",
    "LABEL_COL = \"area\"                         # ← change to \"area\" later on\n",
    "FILE_PATH = r\"FilteredData100.xlsx\"          # your file\n",
    "\n",
    "# -- read the sheet ----------------------------------------------------------\n",
    "df = pd.read_excel(FILE_PATH)[[TEXT_COL, LABEL_COL]].dropna()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# clean up label strings and build the canonical list  -------------\n",
    "# ------------------------------------------------------------------\n",
    "# df[LABEL_COL] = df[LABEL_COL].str.strip()            # remove leading/trailing spaces\n",
    "# label_list  = sorted(df[LABEL_COL].unique())         # canonical list (7 labels)\n",
    "# label2id    = {l: i for i, l in enumerate(label_list)}\n",
    "# id2label    = {i: l for l, i in label2id.items()}\n",
    "# df[\"label\"] = df[LABEL_COL].map(label2id)\n",
    "\n",
    "# print(\"Domain labels:\", label_list)   # sanity-check\n",
    "\n",
    "# Clean area names and build readable names\n",
    "df[LABEL_COL] = df[LABEL_COL].str.strip()\n",
    "\n",
    "def prettify_area(code):\n",
    "    rep = ((\"BIOCHEM\", \"biochemistry\"), (\"MOL\", \"molecular\"), (\"BIOL\", \"biology\"),\n",
    "           (\"CS\", \"computer science\"), (\"NLP\", \"natural language processing\"),\n",
    "           (\"IR\", \"information retrieval\"), (\"EE\", \"electrical engineering\"),\n",
    "           (\"MECH\", \"mechanical engineering\"), (\"MED\", \"medical science\"),\n",
    "           (\"CHEM\", \"chemistry\"), (\"PHY\", \"physics\"))\n",
    "    txt = code.lower().replace('-', ' ')\n",
    "    for a, b in rep:\n",
    "        txt = txt.replace(a.lower(), b)\n",
    "    return txt.replace(\"  \", \" \").strip()\n",
    "\n",
    "label_list  = sorted(df[LABEL_COL].unique())              # 134 areas\n",
    "nice_names  = {label: prettify_area(label) for label in label_list}\n",
    "labels_for_zs = [nice_names[label] for label in label_list]\n",
    "\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "df[\"label\"] = df[LABEL_COL].map(label2id)\n",
    "\n",
    "\n",
    "# -- split 70 / 15 / 15 ------------------------------------------------------\n",
    "train_df, temp_df = train_test_split(\n",
    "        df, test_size=0.30, stratify=df[\"label\"], random_state=SEED)\n",
    "val_df,   test_df = train_test_split(\n",
    "        temp_df, test_size=0.50, stratify=temp_df[\"label\"], random_state=SEED)\n",
    "\n",
    "hf_dset = DatasetDict({\n",
    "    \"train\":      Dataset.from_pandas(train_df[[TEXT_COL, \"label\"]],\n",
    "                                      preserve_index=False),\n",
    "    \"validation\": Dataset.from_pandas(val_df[[TEXT_COL, \"label\"]],\n",
    "                                      preserve_index=False),\n",
    "    \"test\":       Dataset.from_pandas(test_df[[TEXT_COL, \"label\"]],\n",
    "                                      preserve_index=False),\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows   –   {len(label_list)} unique labels:\")\n",
    "print(label_list)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2.  ZERO-SHOT evaluation with MNLI-BERT   (fast: N × 7 only) --------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "mnli = AutoModelForSequenceClassification.from_pretrained(ZS_MODEL_NAME)\n",
    "mnli.config.label2id = {\"contradiction\": 0, \"neutral\": 1, \"entailment\": 2}\n",
    "mnli.config.id2label = {v:k for k,v in mnli.config.label2id.items()}\n",
    "\n",
    "zs_pipe = pipeline(\"zero-shot-classification\",\n",
    "                   model     = mnli,\n",
    "                   tokenizer = ZS_MODEL_NAME,\n",
    "                   device    = 0 if torch.cuda.is_available() else -1,\n",
    "                   batch_size= BATCH_SIZE_ZS)\n",
    "\n",
    "# def zs_predict(texts, labels=label_list):\n",
    "#     preds = []\n",
    "#     for i in tqdm(range(0, len(texts), BATCH_SIZE_ZS), desc=\"zero-shot\"):\n",
    "#         chunk = texts[i:i+BATCH_SIZE_ZS]\n",
    "#         outs  = zs_pipe(chunk,\n",
    "#                         candidate_labels = labels,\n",
    "#                         hypothesis_template = \"This abstract is about {}.\",\n",
    "#                         multi_label=False)\n",
    "#         preds.extend(label2id[o[\"labels\"][0]] for o in outs)\n",
    "#     return preds\n",
    "\n",
    "def zs_predict(texts, labels=labels_for_zs):\n",
    "    preds = []\n",
    "    for i in tqdm(range(0, len(texts), BATCH_SIZE_ZS), desc=\"zero-shot\"):\n",
    "        chunk = texts[i:i+BATCH_SIZE_ZS]\n",
    "        outs = zs_pipe(chunk,\n",
    "                       candidate_labels = labels,\n",
    "                       hypothesis_template = \"This abstract is about {}.\",\n",
    "                       multi_label=False)\n",
    "        for o in outs:\n",
    "            predicted_nl = o[\"labels\"][0]\n",
    "            original = next(k for k, v in nice_names.items() if v == predicted_nl)\n",
    "            preds.append(label2id[original])\n",
    "    return preds\n",
    "\n",
    "\n",
    "metric_acc = evaluate.load(\"accuracy\");  metric_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def eval_zs(split):\n",
    "    refs  = hf_dset[split][\"label\"]\n",
    "    preds = zs_predict(hf_dset[split][TEXT_COL])     # ← changed\n",
    "    return {\n",
    "        \"zero_accuracy\": metric_acc.compute(predictions=preds, references=refs)[\"accuracy\"],\n",
    "        \"zero_macro_f1\": metric_f1.compute(predictions=preds, references=refs,\n",
    "                                           average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "print(\"\\n>>> ZERO-SHOT (domain-level)\")\n",
    "baseline_val  = eval_zs(\"validation\");  print(\"validation:\", baseline_val)\n",
    "baseline_test = eval_zs(\"test\");        print(\"test:      \", baseline_test)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3.  Tokeniser & fine-tune --------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "tok = AutoTokenizer.from_pretrained(ZS_MODEL_NAME)\n",
    "\n",
    "\n",
    "def tok_fn(batch):                       # tokenise *Abstract* column\n",
    "    return tok(batch[TEXT_COL], truncation=True)\n",
    "\n",
    "ds_tok = hf_dset.map(tok_fn, batched=True, remove_columns=[TEXT_COL])\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "collator = DataCollatorWithPadding(tok)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            ZS_MODEL_NAME,\n",
    "            # num_labels = len(dom_names),\n",
    "            num_labels = len(label_list),  # 7-way classification\n",
    "            id2label   = id2label,\n",
    "            label2id   = label2id,\n",
    "            ignore_mismatched_sizes = True)          # swaps 3-way head → 7-way\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=preds,\n",
    "                                       references=labels)[\"accuracy\"],\n",
    "        \"macro_f1\": metric_f1.compute(predictions=preds,\n",
    "                                      references=labels,\n",
    "                                      average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir                 = \"bert_wos_domains\",\n",
    "    learning_rate              = LR,\n",
    "    per_device_train_batch_size= BATCH_SIZE_FT,\n",
    "    per_device_eval_batch_size = BATCH_SIZE_FT,\n",
    "    eval_strategy        = \"epoch\",\n",
    "    save_strategy              = \"epoch\",\n",
    "    num_train_epochs           = EPOCHS,\n",
    "    seed                       = SEED,\n",
    "    weight_decay               = 0.01,\n",
    "    logging_steps              = 100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=args,\n",
    "                  train_dataset = ds_tok[\"train\"],\n",
    "                  eval_dataset  = ds_tok[\"validation\"],\n",
    "                  tokenizer     = tok,\n",
    "                  data_collator = collator,\n",
    "                  compute_metrics = compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n>>> POST-TUNING EVALUATION\")\n",
    "fin_val  = trainer.evaluate(ds_tok[\"validation\"], metric_key_prefix=\"fine\")\n",
    "fin_test = trainer.evaluate(ds_tok[\"test\"],        metric_key_prefix=\"fine\")\n",
    "\n",
    "def compare(before, after, split):\n",
    "    print(f\"\\n=== {split.upper()} ===\")\n",
    "    for m in (\"accuracy\", \"macro_f1\"):\n",
    "        b = before[\"zero_\"+m];  a = after[\"fine_\"+m]\n",
    "        print(f\"{m:>10}: {b:.4f} → {a:.4f}   (Δ {a-b:+.4f})\")\n",
    "\n",
    "compare(baseline_val,  fin_val,  \"validation\")\n",
    "compare(baseline_test, fin_test, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81b058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
